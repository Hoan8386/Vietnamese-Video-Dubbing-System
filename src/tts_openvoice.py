"""
Text-to-Speech v·ªõi OpenVoice - Voice Cloning
Gi·ªØ nguy√™n c·∫£m x√∫c v√† nh·ªãp ƒëi·ªáu t·ª´ video g·ªëc

OpenVoice: Instant voice cloning v·ªõi control t·ªët
- GPU: GTX 1050+ (4GB+ VRAM)
- Clones voice t·ª´ reference audio 
- Gi·ªØ emotion, rhythm, intonation
"""

import os
import json
import torch
import numpy as np
from pathlib import Path
from pydub import AudioSegment
import warnings
warnings.filterwarnings('ignore')


class OpenVoiceTTS:
    """OpenVoice TTS wrapper cho voice cloning"""
    
    def __init__(self, device='auto'):
        """
        Kh·ªüi t·∫°o OpenVoice model
        
        Args:
            device: 'cuda', 'cpu', ho·∫∑c 'auto'
        """
        # Detect device
        if device == 'auto':
            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        else:
            self.device = device
        
        print(f"üéôÔ∏è Kh·ªüi t·∫°o OpenVoice TTS tr√™n {self.device.upper()}...")
        
        # Check CUDA memory n·∫øu c√≥ GPU
        if self.device == 'cuda':
            gpu_mem = torch.cuda.get_device_properties(0).total_memory / (1024**3)
            print(f"   GPU: {torch.cuda.get_device_name(0)}")
            print(f"   VRAM: {gpu_mem:.1f} GB")
            
            # T·ªëi ∆∞u cho GPU
            torch.backends.cudnn.benchmark = True
            torch.backends.cuda.matmul.allow_tf32 = True
        
        self.model = None
        self.tone_converter = None
        self._load_models()
    
    def _load_models(self):
        """Load OpenVoice models (base + tone converter)"""
        try:
            from openvoice import se_extractor
            from openvoice.api import ToneColorConverter, BaseSpeakerTTS
            
            # Model paths
            base_dir = Path(__file__).parent.parent
            ckpt_base = base_dir / 'OpenVoice' / 'checkpoints' / 'base_speakers' / 'EN'
            ckpt_converter = base_dir / 'OpenVoice' / 'checkpoints' / 'converter'
            
            # Load base TTS
            print("   üì• Loading Base TTS model...")
            self.model = BaseSpeakerTTS(
                str(ckpt_base / 'config.json'),
                device=self.device
            )
            self.model.load_ckpt(str(ckpt_base / 'checkpoint.pth'))
            
            # Load Tone Converter (ƒë·ªÉ clone voice)
            print("   üì• Loading Tone Color Converter...")
            self.tone_converter = ToneColorConverter(
                str(ckpt_converter / 'config.json'),
                device=self.device
            )
            self.tone_converter.load_ckpt(str(ckpt_converter / 'checkpoint.pth'))
            
            # SE extractor (ƒë·ªÉ extract voice characteristics)
            self.se_extractor = se_extractor
            
            print("   ‚úÖ Models loaded successfully")
            
        except ImportError:
            print("   ‚ö†Ô∏è OpenVoice ch∆∞a c√†i ƒë·∫∑t!")
            print("   üì¶ C√†i ƒë·∫∑t: pip install git+https://github.com/myshell-ai/OpenVoice.git")
            raise
        except Exception as e:
            print(f"   ‚ùå L·ªói load model: {e}")
            raise
    
    def extract_voice_embedding(self, audio_path, output_path='reference_se.pth'):
        """
        Extract voice embedding t·ª´ audio reference
        
        Args:
            audio_path: ƒê∆∞·ªùng d·∫´n audio g·ªëc (gi·ªçng c·∫ßn clone)
            output_path: ƒê∆∞·ªùng d·∫´n l∆∞u embedding
        
        Returns:
            ƒê∆∞·ªùng d·∫´n file embedding
        """
        print(f"   üéØ Extracting voice characteristics t·ª´: {Path(audio_path).name}")
        
        try:
            # Extract speaker embedding
            target_se, audio_name = self.se_extractor.get_se(
                audio_path,
                self.tone_converter,
                target_dir='processed',
                vad=True  # Voice Activity Detection
            )
            
            # Save embedding
            os.makedirs(os.path.dirname(output_path), exist_ok=True)
            torch.save(target_se, output_path)
            
            print(f"   ‚úÖ Voice embedding saved: {output_path}")
            return output_path
            
        except Exception as e:
            print(f"   ‚ùå L·ªói extract embedding: {e}")
            return None
    
    def synthesize_with_cloning(self, text, reference_se, output_path, 
                                speed=1.0, language='Vietnamese'):
        """
        T·ªïng h·ª£p gi·ªçng n√≥i v·ªõi voice cloning
        
        Args:
            text: Text ti·∫øng Vi·ªát c·∫ßn t·ªïng h·ª£p
            reference_se: ƒê∆∞·ªùng d·∫´n ho·∫∑c tensor c·ªßa reference embedding
            output_path: ƒê∆∞·ªùng d·∫´n l∆∞u audio
            speed: T·ªëc ƒë·ªô n√≥i (0.5-2.0)
            language: Ng√¥n ng·ªØ ('English', 'Vietnamese', 'Chinese')
        """
        try:
            # Load reference embedding n·∫øu l√† path
            if isinstance(reference_se, str):
                reference_se = torch.load(reference_se, map_location=self.device)
            
            # Temporary output (tr∆∞·ªõc khi clone voice)
            temp_output = output_path.replace('.wav', '_temp.wav')
            
            # Step 1: Base TTS synthesis
            # S·ª≠ d·ª•ng base speaker ƒë·ªÉ t·∫°o audio t·∫°m
            base_dir = Path(__file__).parent.parent
            src_path = base_dir / 'OpenVoice' / 'checkpoints' / 'base_speakers' / 'EN' / 'en_default_se.pth'
            
            self.model.tts(
                text,
                temp_output,
                speaker=str(src_path),
                language=language,
                speed=speed
            )
            
            # Step 2: Tone Color Conversion (clone voice)
            # Convert sang gi·ªçng c·ªßa reference
            source_se = torch.load(str(src_path), map_location=self.device)
            
            self.tone_converter.convert(
                audio_src_path=temp_output,
                src_se=source_se,
                tgt_se=reference_se,
                output_path=output_path,
                message="@MyShell"
            )
            
            # Cleanup temp file
            if os.path.exists(temp_output):
                os.remove(temp_output)
            
            return True
            
        except Exception as e:
            print(f"   ‚ùå L·ªói synthesize: {e}")
            return False
    
    def clear_cache(self):
        """X√≥a GPU cache"""
        if self.device == 'cuda':
            torch.cuda.empty_cache()


def extract_segment_audio(original_audio, start_time, end_time, output_path):
    """
    C·∫Øt m·ªôt ƒëo·∫°n audio t·ª´ audio g·ªëc
    D√πng ƒë·ªÉ t·∫°o reference audio cho t·ª´ng segment
    
    Args:
        original_audio: ƒê∆∞·ªùng d·∫´n audio g·ªëc
        start_time: Th·ªùi gian b·∫Øt ƒë·∫ßu (gi√¢y)
        end_time: Th·ªùi gian k·∫øt th√∫c (gi√¢y)
        output_path: ƒê∆∞·ªùng d·∫´n l∆∞u segment
    """
    try:
        audio = AudioSegment.from_file(original_audio)
        
        # Convert to milliseconds
        start_ms = int(start_time * 1000)
        end_ms = int(end_time * 1000)
        
        # Extract segment
        segment = audio[start_ms:end_ms]
        
        # Export
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        segment.export(output_path, format="wav")
        
        return True
    except Exception as e:
        print(f"   ‚ö†Ô∏è L·ªói extract segment: {e}")
        return False


def tts_openvoice_segments(segments_json, original_audio, output_dir, 
                           use_segment_reference=False):
    """
    TTS cho t·∫•t c·∫£ segments v·ªõi OpenVoice voice cloning
    
    Args:
        segments_json: JSON ch·ª©a segments v·ªõi text ti·∫øng Vi·ªát
        original_audio: Audio g·ªëc (ƒë·ªÉ extract voice characteristics)
        output_dir: Th∆∞ m·ª•c l∆∞u audio segments
        use_segment_reference: True = clone t·ª´ng segment ri√™ng, False = clone to√†n b·ªô
    
    Returns:
        True n·∫øu th√†nh c√¥ng
    """
    print("üéôÔ∏è TTS v·ªõi OpenVoice - Voice Cloning...")
    
    try:
        # Load segments
        with open(segments_json, encoding="utf-8") as f:
            segments = json.load(f)
        
        # T·∫°o th∆∞ m·ª•c
        os.makedirs(output_dir, exist_ok=True)
        temp_dir = os.path.join(output_dir, "temp")
        os.makedirs(temp_dir, exist_ok=True)
        
        # Kh·ªüi t·∫°o OpenVoice TTS
        tts = OpenVoiceTTS(device='auto')
        
        # Extract voice embedding t·ª´ audio g·ªëc (to√†n b·ªô video)
        print("\nüìä Extracting voice characteristics t·ª´ video g·ªëc...")
        global_se_path = os.path.join(temp_dir, "global_voice_embedding.pth")
        if not use_segment_reference:
            tts.extract_voice_embedding(original_audio, global_se_path)
        
        print(f"\nüéµ T·ªïng h·ª£p {len(segments)} segments...")
        
        success_count = 0
        failed_segments = []
        
        for i, seg in enumerate(segments):
            vi_text = seg.get("vi_text", "").strip()
            
            if not vi_text:
                print(f"  [{i+1}/{len(segments)}] ‚ö†Ô∏è Segment r·ªóng, b·ªè qua")
                continue
            
            output_path = os.path.join(output_dir, f"segment_{i:04d}.wav")
            
            try:
                # Ch·ªçn reference embedding
                if use_segment_reference:
                    # Clone t·ª´ng segment ri√™ng (ch√≠nh x√°c h∆°n nh∆∞ng ch·∫≠m h∆°n)
                    seg_audio = os.path.join(temp_dir, f"ref_{i:04d}.wav")
                    
                    # Extract audio segment g·ªëc
                    if extract_segment_audio(original_audio, seg["start"], seg["end"], seg_audio):
                        # Extract embedding cho segment n√†y
                        se_path = os.path.join(temp_dir, f"se_{i:04d}.pth")
                        tts.extract_voice_embedding(seg_audio, se_path)
                    else:
                        # Fallback to global
                        se_path = global_se_path
                else:
                    # Clone t·ª´ to√†n b·ªô audio (nhanh h∆°n, quality v·∫´n t·ªët)
                    se_path = global_se_path
                
                # T√≠nh t·ªëc ƒë·ªô n√≥i
                duration = seg["end"] - seg["start"]
                char_count = len(vi_text)
                # ∆Ø·ªõc l∆∞·ª£ng: ~5 k√Ω t·ª±/gi√¢y cho ti·∫øng Vi·ªát ·ªü t·ªëc ƒë·ªô b√¨nh th∆∞·ªùng
                estimated_duration = char_count / 5.0
                speed = estimated_duration / duration if duration > 0 else 1.0
                speed = max(0.5, min(2.0, speed))  # Gi·ªõi h·∫°n 0.5-2.0x
                
                # Synthesize v·ªõi voice cloning
                success = tts.synthesize_with_cloning(
                    vi_text,
                    se_path,
                    output_path,
                    speed=speed,
                    language='Vietnamese'
                )
                
                if success:
                    # L∆∞u path v√†o segment
                    seg["vi_audio_path"] = output_path
                    success_count += 1
                    print(f"  [{i+1}/{len(segments)}] ‚úÖ {seg['start']:.1f}s-{seg['end']:.1f}s | Speed: {speed:.2f}x")
                else:
                    failed_segments.append(i)
                    print(f"  [{i+1}/{len(segments)}] ‚ùå Failed")
                
                # Clear cache m·ªói 10 segments
                if (i + 1) % 10 == 0:
                    tts.clear_cache()
                
            except Exception as e:
                print(f"  [{i+1}/{len(segments)}] ‚ùå L·ªói: {e}")
                failed_segments.append(i)
        
        # Update JSON v·ªõi audio paths
        with open(segments_json, "w", encoding="utf-8") as f:
            json.dump(segments, f, ensure_ascii=False, indent=2)
        
        print(f"\n‚úÖ TTS ho√†n t·∫•t:")
        print(f"   - Th√†nh c√¥ng: {success_count}/{len(segments)}")
        if failed_segments:
            print(f"   - Th·∫•t b·∫°i: {len(failed_segments)} segments: {failed_segments[:10]}")
        
        return success_count > 0
        
    except Exception as e:
        print(f"‚ùå L·ªói TTS: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    # Test
    tts_openvoice_segments(
        "../subtitles/vi.json",
        "../audio/original.wav",
        "../audio/vi_segments"
    )
