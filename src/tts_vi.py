import edge_tts
import asyncio
import os
import json


# Danh s√°ch gi·ªçng ti·∫øng Vi·ªát c·ªßa Edge TTS
VIETNAMESE_VOICES = {
    "female": "vi-VN-HoaiMyNeural",  # Gi·ªçng n·ªØ (m·∫∑c ƒë·ªãnh)
    "male": "vi-VN-NamMinhNeural"    # Gi·ªçng nam
}


async def _tts_single_with_prosody(text, output_path, voice="female", rate="+0%", pitch="+0Hz"):
    """
    Helper async function ƒë·ªÉ TTS m·ªôt c√¢u v·ªõi prosody control
    
    Args:
        text: Text c·∫ßn TTS
        output_path: ƒê∆∞·ªùng d·∫´n output
        voice: "female" ho·∫∑c "male"
        rate: Speech rate adjustment (e.g., "+10%", "-5%")
        pitch: Pitch adjustment (e.g., "+5Hz", "-10Hz")
    """
    voice_name = VIETNAMESE_VOICES.get(voice, VIETNAMESE_VOICES["female"])
    
    # T·∫°o SSML v·ªõi prosody tags ƒë·ªÉ ƒëi·ªÅu ch·ªânh rate v√† pitch
    if rate != "+0%" or pitch != "+0Hz":
        ssml_text = f"""
        <speak version="1.0" xmlns="http://www.w3.org/2001/10/synthesis" xml:lang="vi-VN">
            <voice name="{voice_name}">
                <prosody rate="{rate}" pitch="{pitch}">
                    {text}
                </prosody>
            </voice>
        </speak>
        """
        communicate = edge_tts.Communicate(ssml_text, voice_name)
    else:
        communicate = edge_tts.Communicate(text, voice_name)
    
    await communicate.save(output_path)


async def _tts_single(text, output_path, voice="female"):
    """Helper async function ƒë·ªÉ TTS m·ªôt c√¢u (backward compatibility)"""
    await _tts_single_with_prosody(text, output_path, voice, "+0%", "+0Hz")


def tts_segments(segments_json, out_dir, voice="female", auto_voice=True):
    """
    Chuy·ªÉn ƒë·ªïi text ti·∫øng Vi·ªát th√†nh gi·ªçng n√≥i b·∫±ng Edge TTS
    H·ªó tr·ª£ t·ª± ƒë·ªông ch·ªçn gi·ªçng nam/n·ªØ v√† ƒëi·ªÅu ch·ªânh prosody
    
    Args:
        segments_json: ƒê∆∞·ªùng d·∫´n JSON ch·ª©a segments ƒë√£ d·ªãch
        out_dir: Th∆∞ m·ª•c output ch·ª©a c√°c file audio
        voice: "female" ho·∫∑c "male" (m·∫∑c ƒë·ªãnh khi auto_voice=False)
        auto_voice: T·ª± ƒë·ªông ch·ªçn gi·ªçng nam/n·ªØ t·ª´ voice_gender (default: True)
    """
    print(f"üó£Ô∏è ƒêang kh·ªüi t·∫°o Edge TTS ti·∫øng Vi·ªát...")
    if auto_voice:
        print(f"   üìä Ch·∫ø ƒë·ªô: T·ª± ƒë·ªông ch·ªçn gi·ªçng nam/n·ªØ + ƒëi·ªÅu ch·ªânh emotion")
    else:
        print(f"   üìä Ch·∫ø ƒë·ªô: Gi·ªçng c·ªë ƒë·ªãnh ({voice})")
    
    try:
        # Load segments
        with open(segments_json, encoding="utf-8") as f:
            segments = json.load(f)
        
        # T·∫°o th∆∞ m·ª•c output
        os.makedirs(out_dir, exist_ok=True)
        
        print(f"üéôÔ∏è ƒêang t·ªïng h·ª£p gi·ªçng n√≥i cho {len(segments)} c√¢u...")
        
        # TTS cho t·ª´ng segment
        for i, seg in enumerate(segments):
            if seg.get("vi_text", "").strip():
                wav_path = os.path.join(out_dir, f"{i:04d}.mp3")
                
                try:
                    # L·∫•y voice info t·ª´ ph√¢n t√≠ch (n·∫øu c√≥)
                    if auto_voice and "voice_gender" in seg:
                        selected_voice = seg["voice_gender"]
                        rate_adjust = seg.get("tts_rate_adjust", "+0%")
                        emotion = seg.get("voice_emotion", "neutral")
                        
                        # ƒêi·ªÅu ch·ªânh pitch theo emotion
                        if emotion == "excited":
                            pitch_adjust = "+5Hz"
                        elif emotion == "calm":
                            pitch_adjust = "-5Hz"
                        else:
                            pitch_adjust = "+0Hz"
                        
                        print(f"  [{i+1}/{len(segments)}] üé§ {selected_voice.upper()} | "
                              f"{emotion} | Rate: {rate_adjust}")
                    else:
                        selected_voice = voice
                        rate_adjust = "+0%"
                        pitch_adjust = "+0Hz"
                    
                    # Ch·∫°y async TTS v·ªõi prosody
                    asyncio.run(_tts_single_with_prosody(
                        seg["vi_text"], 
                        wav_path, 
                        selected_voice,
                        rate_adjust,
                        pitch_adjust
                    ))
                    
                    # L∆∞u ƒë∆∞·ªùng d·∫´n v√†o segment
                    seg["vi_audio_path"] = wav_path
                    
                    if not auto_voice or "voice_gender" not in seg:
                        print(f"  [{i+1}/{len(segments)}] ‚úÖ {seg['vi_text'][:40]}...")
                    
                except Exception as e:
                    print(f"  ‚ö†Ô∏è L·ªói TTS c√¢u {i+1}: {e}")
                    seg["vi_audio_path"] = None
            else:
                seg["vi_audio_path"] = None
        
        # L∆∞u l·∫°i segments v·ªõi ƒë∆∞·ªùng d·∫´n audio
        with open(segments_json, "w", encoding="utf-8") as f:
            json.dump(segments, f, ensure_ascii=False, indent=2)
        
        print(f"‚úÖ TTS ho√†n t·∫•t. Audio l∆∞u t·∫°i: {out_dir}")
        return True
        
    except Exception as e:
        print(f"‚ùå L·ªói TTS: {e}")
        return False


if __name__ == "__main__":
    # Test
    tts_segments("../subtitles/vi.json", "../audio/vi_segments")
