"""
Voice Cloning Module using OpenVoice
Clone giá»ng tá»« video input vÃ  dÃ¹ng Ä‘á»ƒ TTS tiáº¿ng Viá»‡t
"""
import os
import json
import torch
import torchaudio
from pathlib import Path


class VoiceCloner:
    """
    Voice Cloning vá»›i OpenVoice
    Zero-shot voice cloning: KhÃ´ng cáº§n training
    """
    
    def __init__(self, device="cpu"):
        """
        Khá»Ÿi táº¡o Voice Cloner
        
        Args:
            device: "cuda" hoáº·c "cpu"
        """
        self.device = device
        self.model = None
        self.tone_color_converter = None
        
        print(f"ðŸŽ¤ Khá»Ÿi táº¡o Voice Cloner (device: {device})...")
        
    def load_models(self):
        """Load OpenVoice models"""
        try:
            # Import OpenVoice (cáº§n cÃ i Ä‘áº·t riÃªng)
            from openvoice import se_extractor
            from openvoice.api import ToneColorConverter, BaseSpeakerTTS
            
            # Load Base TTS model
            print("ðŸ“¥ Äang táº£i Base TTS model...")
            self.base_speaker = BaseSpeakerTTS(
                'checkpoints/base_speakers/EN/config.json',
                device=self.device
            )
            
            # Load Tone Color Converter
            print("ðŸ“¥ Äang táº£i Tone Color Converter...")
            self.tone_converter = ToneColorConverter(
                'checkpoints/converter/config.json',
                device=self.device
            )
            
            # Load SE Extractor (Speaker Embedding)
            print("ðŸ“¥ Äang táº£i Speaker Embedding Extractor...")
            self.se_extractor = se_extractor.get_se_model(device=self.device)
            
            print("âœ… Models loaded successfully!")
            return True
            
        except ImportError:
            print("âŒ OpenVoice chÆ°a Ä‘Æ°á»£c cÃ i Ä‘áº·t!")
            print("ðŸ“¦ CÃ i Ä‘áº·t: pip install git+https://github.com/myshell-ai/OpenVoice.git")
            return False
        except Exception as e:
            print(f"âŒ Lá»—i load models: {e}")
            return False
    
    def extract_speaker_embedding(self, reference_audio, output_path="se.pth"):
        """
        TrÃ­ch xuáº¥t speaker embedding tá»« audio reference
        
        Args:
            reference_audio: ÄÆ°á»ng dáº«n audio gá»‘c (tá»« video input)
            output_path: NÆ¡i lÆ°u speaker embedding
        
        Returns:
            Path to speaker embedding file
        """
        print(f"ðŸŽ¯ Äang trÃ­ch xuáº¥t speaker embedding tá»«: {reference_audio}")
        
        try:
            from openvoice import se_extractor
            
            # Extract speaker embedding
            se = se_extractor.get_se(
                reference_audio,
                self.se_extractor,
                target_dir=os.path.dirname(output_path)
            )
            
            # Save embedding
            torch.save(se, output_path)
            
            print(f"âœ… Speaker embedding saved: {output_path}")
            return output_path
            
        except Exception as e:
            print(f"âŒ Lá»—i extract speaker embedding: {e}")
            return None
    
    def clone_voice_tts(self, text, speaker_embedding, output_audio, language="Vietnamese"):
        """
        TTS vá»›i cloned voice
        
        Args:
            text: Text tiáº¿ng Viá»‡t cáº§n TTS
            speaker_embedding: Path to speaker embedding file
            output_audio: Output audio path
            language: NgÃ´n ngá»¯ (default: Vietnamese)
        """
        try:
            # Load speaker embedding
            target_se = torch.load(speaker_embedding).to(self.device)
            
            # Generate speech vá»›i base model
            temp_audio = output_audio.replace('.wav', '_temp.wav')
            self.base_speaker.tts(
                text,
                temp_audio,
                speaker='default',
                language=language
            )
            
            # Convert tone color (voice cloning)
            self.tone_converter.convert(
                audio_src_path=temp_audio,
                src_se=self.base_speaker.source_se,
                tgt_se=target_se,
                output_path=output_audio
            )
            
            # Clean up temp file
            if os.path.exists(temp_audio):
                os.remove(temp_audio)
            
            return True
            
        except Exception as e:
            print(f"âŒ Lá»—i TTS: {e}")
            return False


def tts_with_voice_cloning(segments_json, reference_audio, out_dir):
    """
    TTS segments vá»›i voice cloning tá»« audio gá»‘c
    
    Args:
        segments_json: JSON chá»©a segments Ä‘Ã£ dá»‹ch
        reference_audio: Audio gá»‘c tá»« video (Ä‘á»ƒ clone giá»ng)
        out_dir: ThÆ° má»¥c output
    """
    print("=" * 60)
    print("ðŸŽ¤ VOICE CLONING TTS")
    print("=" * 60)
    
    # Kiá»ƒm tra device
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"ðŸ–¥ï¸ Device: {device.upper()}")
    
    if device == "cpu":
        print("âš ï¸ Cháº¡y trÃªn CPU sáº½ cháº­m (30-60s/cÃ¢u)")
        print("ðŸ’¡ Äá»ƒ nhanh hÆ¡n, dÃ¹ng GPU vá»›i CUDA")
    
    # Khá»Ÿi táº¡o Voice Cloner
    cloner = VoiceCloner(device=device)
    
    if not cloner.load_models():
        print("âŒ KhÃ´ng thá»ƒ load models. Quay vá» Edge TTS...")
        return False
    
    # Extract speaker embedding tá»« audio gá»‘c
    print(f"\nðŸŽ¯ Äang phÃ¢n tÃ­ch giá»ng nÃ³i tá»« video gá»‘c...")
    se_path = os.path.join(out_dir, "speaker_embedding.pth")
    
    if not cloner.extract_speaker_embedding(reference_audio, se_path):
        print("âŒ KhÃ´ng thá»ƒ extract speaker embedding")
        return False
    
    print(f"âœ… ÄÃ£ clone giá»ng tá»« video gá»‘c!")
    
    # Load segments
    with open(segments_json, encoding="utf-8") as f:
        segments = json.load(f)
    
    # Táº¡o thÆ° má»¥c output
    os.makedirs(out_dir, exist_ok=True)
    
    print(f"\nðŸŽ™ï¸ Äang tá»•ng há»£p giá»ng nÃ³i cho {len(segments)} cÃ¢u...")
    print("â±ï¸ Thá»i gian Æ°á»›c tÃ­nh: ~{:.0f} phÃºt".format(len(segments) * 0.5))
    
    # TTS tá»«ng segment vá»›i cloned voice
    success_count = 0
    for i, seg in enumerate(segments):
        if seg.get("vi_text", "").strip():
            wav_path = os.path.join(out_dir, f"{i:04d}.wav")
            
            try:
                print(f"\n[{i+1}/{len(segments)}] ðŸŽ¤ Cloning: {seg['vi_text'][:50]}...")
                
                if cloner.clone_voice_tts(seg["vi_text"], se_path, wav_path):
                    seg["vi_audio_path"] = wav_path
                    success_count += 1
                    print(f"  âœ… Success")
                else:
                    seg["vi_audio_path"] = None
                    print(f"  âŒ Failed")
                    
            except Exception as e:
                print(f"  âš ï¸ Lá»—i: {e}")
                seg["vi_audio_path"] = None
        else:
            seg["vi_audio_path"] = None
    
    # LÆ°u láº¡i segments
    with open(segments_json, "w", encoding="utf-8") as f:
        json.dump(segments, f, ensure_ascii=False, indent=2)
    
    print("\n" + "=" * 60)
    print(f"âœ… TTS hoÃ n táº¥t: {success_count}/{len(segments)} cÃ¢u")
    print(f"ðŸ“ Audio lÆ°u táº¡i: {out_dir}")
    print("=" * 60)
    
    return success_count > 0


if __name__ == "__main__":
    # Test
    tts_with_voice_cloning(
        "../subtitles/vi.json",
        "../audio/original.wav",
        "../audio/vi_segments_cloned"
    )
