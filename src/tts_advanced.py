"""
Advanced TTS with Audio Mixing
Mix original audio with Vietnamese TTS to preserve emotion
"""
import os
import json
from pydub import AudioSegment
from pydub.effects import normalize
import edge_tts
import asyncio
from text_cleaner import clean_text_for_tts, validate_text


# Danh s√°ch gi·ªçng ti·∫øng Vi·ªát
VIETNAMESE_VOICES = {
    "female": "vi-VN-HoaiMyNeural",
    "male": "vi-VN-NamMinhNeural"
}


async def _tts_with_ssml(text, output_path, voice="female", rate="+0%", pitch="+0Hz", volume="+0%"):
    """
    TTS ƒë∆°n gi·∫£n v·ªõi parameters tr·ª±c ti·∫øp (kh√¥ng d√πng SSML)
    """
    voice_name = VIETNAMESE_VOICES.get(voice, VIETNAMESE_VOICES["female"])
    
    # D√πng plain text v·ªõi parameters - Edge TTS s·∫Ω t·ª± x·ª≠ l√Ω
    communicate = edge_tts.Communicate(
        text=text,
        voice=voice_name,
        rate=rate,
        pitch=pitch,
        volume=volume
    )
    await communicate.save(output_path)


def extract_segment_audio(original_audio_path, start_time, end_time, output_path):
    """
    Tr√≠ch xu·∫•t m·ªôt segment audio t·ª´ audio g·ªëc
    
    Args:
        original_audio_path: Audio g·ªëc
        start_time: Th·ªùi gian b·∫Øt ƒë·∫ßu (seconds)
        end_time: Th·ªùi gian k·∫øt th√∫c (seconds)
        output_path: ƒê∆∞·ªùng d·∫´n output
    """
    try:
        audio = AudioSegment.from_file(original_audio_path)
        
        # Extract segment
        start_ms = int(start_time * 1000)
        end_ms = int(end_time * 1000)
        segment = audio[start_ms:end_ms]
        
        # Export
        segment.export(output_path, format="wav")
        return True
    except Exception as e:
        print(f"  ‚ö†Ô∏è L·ªói extract segment: {e}")
        return False


def mix_audio_segments(original_segment, tts_segment, output_path, tts_volume=1.0, original_volume=0.2):
    """
    Mix audio g·ªëc (gi·∫£m volume) v·ªõi TTS ƒë·ªÉ gi·ªØ background emotion
    
    Args:
        original_segment: Audio g·ªëc c·ªßa segment
        tts_segment: Audio TTS ti·∫øng Vi·ªát
        output_path: Output path
        tts_volume: Volume c·ªßa TTS (0.0-1.0)
        original_volume: Volume c·ªßa audio g·ªëc (0.0-0.5) - nh·ªè ƒë·ªÉ l√†m background
    """
    try:
        # Load both audio
        original = AudioSegment.from_file(original_segment)
        tts = AudioSegment.from_file(tts_segment)
        
        # ƒêi·ªÅu ch·ªânh volume
        original_bg = original - (60 - int(original_volume * 60))  # Gi·∫£m volume original
        tts_main = tts - (60 - int(tts_volume * 60))
        
        # Normalize
        original_bg = normalize(original_bg)
        tts_main = normalize(tts_main)
        
        # Match duration
        if len(tts_main) > len(original_bg):
            # TTS d√†i h∆°n ‚Üí pad original
            silence = AudioSegment.silent(duration=len(tts_main) - len(original_bg))
            original_bg = original_bg + silence
        else:
            # Original d√†i h∆°n ‚Üí truncate
            original_bg = original_bg[:len(tts_main)]
        
        # Mix (overlay)
        mixed = original_bg.overlay(tts_main)
        
        # Export
        mixed.export(output_path, format="mp3")
        return True
        
    except Exception as e:
        print(f"  ‚ö†Ô∏è L·ªói mix audio: {e}")
        return False


def tts_segments_advanced(segments_json, original_audio, out_dir, auto_voice=True, enable_mixing=False):
    """
    TTS n√¢ng cao v·ªõi:
    - Auto gender selection
    - Prosody control d·ª±a tr√™n emotion
    - Optional: Mix v·ªõi audio g·ªëc ƒë·ªÉ gi·ªØ emotion
    
    Args:
        segments_json: JSON ch·ª©a segments
        original_audio: Audio g·ªëc (ƒë·ªÉ extract background)
        out_dir: Output directory
        auto_voice: T·ª± ƒë·ªông ch·ªçn gi·ªçng nam/n·ªØ
        enable_mixing: Mix audio g·ªëc v·ªõi TTS (experimental)
    """
    print("üó£Ô∏è ƒêang kh·ªüi t·∫°o Advanced TTS...")
    print(f"   üìä Auto voice: {auto_voice}")
    print(f"   üéµ Audio mixing: {'Enabled' if enable_mixing else 'Disabled'}")
    
    try:
        # Load segments
        with open(segments_json, encoding="utf-8") as f:
            segments = json.load(f)
        
        # T·∫°o th∆∞ m·ª•c
        os.makedirs(out_dir, exist_ok=True)
        temp_dir = os.path.join(out_dir, "temp")
        os.makedirs(temp_dir, exist_ok=True)
        
        print(f"üéôÔ∏è ƒêang t·ªïng h·ª£p gi·ªçng n√≥i cho {len(segments)} c√¢u...")
        
        for i, seg in enumerate(segments):
            if not seg.get("vi_text", "").strip():
                seg["vi_audio_path"] = None
                continue
            
            # Clean v√† validate text tr∆∞·ªõc khi TTS
            is_valid, cleaned_text, warning = validate_text(seg["vi_text"])
            
            if not is_valid:
                print(f"  [{i+1}/{len(segments)}] ‚ö†Ô∏è Skip: {warning}")
                seg["vi_audio_path"] = None
                continue
            
            if warning:
                print(f"  [{i+1}/{len(segments)}] ‚ö†Ô∏è {warning}")
            
            # C·∫≠p nh·∫≠t text ƒë√£ clean
            seg["vi_text_cleaned"] = cleaned_text
            
            final_path = os.path.join(out_dir, f"{i:04d}.mp3")
            
            try:
                # 1. L·∫•y voice info
                if auto_voice and "voice_gender" in seg:
                    voice = seg["voice_gender"]
                    rate = seg.get("tts_rate_adjust", "+0%")
                    emotion = seg.get("voice_emotion", "neutral")
                    
                    # ƒêi·ªÅu ch·ªânh pitch theo emotion
                    if emotion == "excited":
                        pitch = "+8Hz"
                        volume = "+5%"
                    elif emotion == "calm":
                        pitch = "-5Hz"
                        volume = "-5%"
                    elif emotion == "urgent":
                        pitch = "+3Hz"
                        volume = "+10%"
                    else:
                        pitch = "+0Hz"
                        volume = "+0%"
                else:
                    voice = "female"
                    rate = "+0%"
                    pitch = "+0Hz"
                    volume = "+0%"
                    emotion = "neutral"
                
                # 2. Generate TTS v·ªõi cleaned text
                tts_temp = os.path.join(temp_dir, f"{i:04d}_tts.mp3")
                asyncio.run(_tts_with_ssml(
                    cleaned_text,  # D√πng cleaned text
                    tts_temp,
                    voice,
                    rate,
                    pitch,
                    volume
                ))
                
                # 3. Mix v·ªõi audio g·ªëc n·∫øu enabled
                if enable_mixing:
                    # Extract original segment
                    orig_segment = os.path.join(temp_dir, f"{i:04d}_orig.wav")
                    if extract_segment_audio(original_audio, seg["start"], seg["end"], orig_segment):
                        # Mix
                        if mix_audio_segments(orig_segment, tts_temp, final_path):
                            print(f"  [{i+1}/{len(segments)}] üéµ {voice.upper()} | "
                                  f"{emotion} | MIXED")
                        else:
                            # Fallback: d√πng TTS only
                            os.rename(tts_temp, final_path)
                            print(f"  [{i+1}/{len(segments)}] üé§ {voice.upper()} | "
                                  f"{emotion} | TTS only")
                    else:
                        os.rename(tts_temp, final_path)
                        print(f"  [{i+1}/{len(segments)}] üé§ {voice.upper()} | "
                              f"{emotion} | TTS only")
                else:
                    # Ch·ªâ d√πng TTS
                    os.rename(tts_temp, final_path)
                    if auto_voice and "voice_gender" in seg:
                        print(f"  [{i+1}/{len(segments)}] üé§ {voice.upper()} | "
                              f"{emotion} | Rate: {rate}")
                    else:
                        print(f"  [{i+1}/{len(segments)}] ‚úÖ {seg['vi_text'][:40]}...")
                
                seg["vi_audio_path"] = final_path
                
            except Exception as e:
                print(f"  ‚ö†Ô∏è L·ªói TTS c√¢u {i+1}: {e}")
                seg["vi_audio_path"] = None
        
        # L∆∞u l·∫°i
        with open(segments_json, "w", encoding="utf-8") as f:
            json.dump(segments, f, ensure_ascii=False, indent=2)
        
        # Cleanup temp
        try:
            import shutil
            shutil.rmtree(temp_dir)
        except:
            pass
        
        print(f"‚úÖ TTS ho√†n t·∫•t. Audio l∆∞u t·∫°i: {out_dir}")
        return True
        
    except Exception as e:
        print(f"‚ùå L·ªói TTS: {e}")
        return False


if __name__ == "__main__":
    # Test
    tts_segments_advanced(
        "../subtitles/vi.json",
        "../audio/original.wav",
        "../audio/vi_segments",
        auto_voice=True,
        enable_mixing=True
    )
